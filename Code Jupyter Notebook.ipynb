{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7647584,"sourceType":"datasetVersion","datasetId":4457859}],"dockerImageVersionId":30675,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:28.643378Z","iopub.execute_input":"2024-03-25T05:45:28.644324Z","iopub.status.idle":"2024-03-25T05:45:29.707122Z","shell.execute_reply.started":"2024-03-25T05:45:28.644292Z","shell.execute_reply":"2024-03-25T05:45:29.706064Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/topic-modeling-articles-dataset/Train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:29.708531Z","iopub.execute_input":"2024-03-25T05:45:29.708937Z","iopub.status.idle":"2024-03-25T05:45:30.059692Z","shell.execute_reply.started":"2024-03-25T05:45:29.708910Z","shell.execute_reply":"2024-03-25T05:45:30.058324Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:30.060986Z","iopub.execute_input":"2024-03-25T05:45:30.061249Z","iopub.status.idle":"2024-03-25T05:45:30.070170Z","shell.execute_reply.started":"2024-03-25T05:45:30.061226Z","shell.execute_reply":"2024-03-25T05:45:30.068890Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(14004, 31)"},"metadata":{}}]},{"cell_type":"code","source":"df = df.iloc[:,:6]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:30.072542Z","iopub.execute_input":"2024-03-25T05:45:30.072860Z","iopub.status.idle":"2024-03-25T05:45:30.097544Z","shell.execute_reply.started":"2024-03-25T05:45:30.072833Z","shell.execute_reply":"2024-03-25T05:45:30.096012Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"     id                                           ABSTRACT  Computer Science  \\\n0  1824  a ever-growing datasets inside observational a...                 0   \n1  3094  we propose the framework considering optimal $...                 1   \n2  8463  nanostructures with open shell transition meta...                 0   \n3  2082  stars are self-gravitating fluids inside which...                 0   \n4  8687  deep neural perception and control networks ar...                 1   \n\n   Mathematics  Physics  Statistics  \n0            0        1           0  \n1            0        0           0  \n2            0        1           0  \n3            0        1           0  \n4            0        0           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ABSTRACT</th>\n      <th>Computer Science</th>\n      <th>Mathematics</th>\n      <th>Physics</th>\n      <th>Statistics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1824</td>\n      <td>a ever-growing datasets inside observational a...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3094</td>\n      <td>we propose the framework considering optimal $...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8463</td>\n      <td>nanostructures with open shell transition meta...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2082</td>\n      <td>stars are self-gravitating fluids inside which...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8687</td>\n      <td>deep neural perception and control networks ar...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Input - output split","metadata":{}},{"cell_type":"code","source":"X = df[\"ABSTRACT\"]\ny = df.iloc[:,2:]","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:30.099190Z","iopub.execute_input":"2024-03-25T05:45:30.099597Z","iopub.status.idle":"2024-03-25T05:45:30.105456Z","shell.execute_reply.started":"2024-03-25T05:45:30.099563Z","shell.execute_reply":"2024-03-25T05:45:30.104730Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Train - test split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:30.106442Z","iopub.execute_input":"2024-03-25T05:45:30.107249Z","iopub.status.idle":"2024-03-25T05:45:31.390409Z","shell.execute_reply.started":"2024-03-25T05:45:30.107220Z","shell.execute_reply":"2024-03-25T05:45:31.389216Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X_train = pd.DataFrame(X_train)\nX_test = pd.DataFrame(X_test)\ny_train = pd.DataFrame(y_train)\ny_test = pd.DataFrame(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:31.393996Z","iopub.execute_input":"2024-03-25T05:45:31.394314Z","iopub.status.idle":"2024-03-25T05:45:31.400645Z","shell.execute_reply.started":"2024-03-25T05:45:31.394286Z","shell.execute_reply":"2024-03-25T05:45:31.399736Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"y1_train = pd.DataFrame(y_train.iloc[:,0])\ny2_train = pd.DataFrame(y_train.iloc[:,1])\ny3_train = pd.DataFrame(y_train.iloc[:,2])\ny4_train = pd.DataFrame(y_train.iloc[:,3])\ny1_test = pd.DataFrame(y_test.iloc[:,0])\ny2_test = pd.DataFrame(y_test.iloc[:,1])\ny3_test = pd.DataFrame(y_test.iloc[:,2])\ny4_test = pd.DataFrame(y_test.iloc[:,3])","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:31.401724Z","iopub.execute_input":"2024-03-25T05:45:31.402081Z","iopub.status.idle":"2024-03-25T05:45:31.414839Z","shell.execute_reply.started":"2024-03-25T05:45:31.402051Z","shell.execute_reply":"2024-03-25T05:45:31.412991Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Analyzing output variables","metadata":{}},{"cell_type":"code","source":"y.sum(axis = 1).value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:31.416288Z","iopub.execute_input":"2024-03-25T05:45:31.416611Z","iopub.status.idle":"2024-03-25T05:45:31.435603Z","shell.execute_reply.started":"2024-03-25T05:45:31.416584Z","shell.execute_reply":"2024-03-25T05:45:31.434775Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"1    11800\n2     2047\n3      157\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"for i in range(4):\n    print(y_train.iloc[:,i].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:31.438264Z","iopub.execute_input":"2024-03-25T05:45:31.439397Z","iopub.status.idle":"2024-03-25T05:45:31.448858Z","shell.execute_reply.started":"2024-03-25T05:45:31.439341Z","shell.execute_reply":"2024-03-25T05:45:31.447714Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Computer Science\n0    6511\n1    4692\nName: count, dtype: int64\nMathematics\n0    8932\n1    2271\nName: count, dtype: int64\nPhysics\n0    8116\n1    3087\nName: count, dtype: int64\nStatistics\n0    8194\n1    3009\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Analysing input variables","metadata":{}},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:31.449854Z","iopub.execute_input":"2024-03-25T05:45:31.450361Z","iopub.status.idle":"2024-03-25T05:45:31.457216Z","shell.execute_reply.started":"2024-03-25T05:45:31.450337Z","shell.execute_reply":"2024-03-25T05:45:31.456085Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(11203, 1)"},"metadata":{}}]},{"cell_type":"code","source":"words_count = []\nfor i in range(X_train.shape[0]):\n    words_count += [len(X_train.iloc[i,0].split())]\nnp.mean(words_count)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:31.458381Z","iopub.execute_input":"2024-03-25T05:45:31.458667Z","iopub.status.idle":"2024-03-25T05:45:31.793310Z","shell.execute_reply.started":"2024-03-25T05:45:31.458640Z","shell.execute_reply":"2024-03-25T05:45:31.792113Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"157.70507899669732"},"metadata":{}}]},{"cell_type":"markdown","source":"Average word counts of the `extracts` are not very large, and we have very less number of samples. So, Deep Leaning Based Algorithms will not be able to perform well. So, going with non-sequential models like Tree Based Algorithms and Naive Bayes.","metadata":{}},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"markdown","source":"## Lowercasing","metadata":{}},{"cell_type":"code","source":"X_train[\"ABSTRACT\"] = X_train[\"ABSTRACT\"].str.lower()\nX_test[\"ABSTRACT\"] = X_test[\"ABSTRACT\"].str.lower()\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:31.794570Z","iopub.execute_input":"2024-03-25T05:45:31.794901Z","iopub.status.idle":"2024-03-25T05:45:31.832101Z","shell.execute_reply.started":"2024-03-25T05:45:31.794874Z","shell.execute_reply":"2024-03-25T05:45:31.831027Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                ABSTRACT\n10864  recent work has explored a syntactic abilities...\n6518   this research presents an innovative and uniqu...\n11212  recently, a fabrication of cdse nanoplatelets ...\n3589   we present the simple, self-consistent model t...\n6927   imposing constraints on a output of the deep n...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABSTRACT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10864</th>\n      <td>recent work has explored a syntactic abilities...</td>\n    </tr>\n    <tr>\n      <th>6518</th>\n      <td>this research presents an innovative and uniqu...</td>\n    </tr>\n    <tr>\n      <th>11212</th>\n      <td>recently, a fabrication of cdse nanoplatelets ...</td>\n    </tr>\n    <tr>\n      <th>3589</th>\n      <td>we present the simple, self-consistent model t...</td>\n    </tr>\n    <tr>\n      <th>6927</th>\n      <td>imposing constraints on a output of the deep n...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Removing Punctuations","metadata":{}},{"cell_type":"code","source":"import string\nstring.punctuation","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:31.833560Z","iopub.execute_input":"2024-03-25T05:45:31.833911Z","iopub.status.idle":"2024-03-25T05:45:31.845984Z","shell.execute_reply.started":"2024-03-25T05:45:31.833886Z","shell.execute_reply":"2024-03-25T05:45:31.844540Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"},"metadata":{}}]},{"cell_type":"code","source":"exclude = string.punctuation","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:31.847293Z","iopub.execute_input":"2024-03-25T05:45:31.847574Z","iopub.status.idle":"2024-03-25T05:45:31.856739Z","shell.execute_reply.started":"2024-03-25T05:45:31.847551Z","shell.execute_reply":"2024-03-25T05:45:31.855682Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def remove_punc(text):\n    for char in exclude:\n        if char in text:\n            text = text.replace(char,\" \")\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:31.858248Z","iopub.execute_input":"2024-03-25T05:45:31.859002Z","iopub.status.idle":"2024-03-25T05:45:31.869481Z","shell.execute_reply.started":"2024-03-25T05:45:31.858959Z","shell.execute_reply":"2024-03-25T05:45:31.867911Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"X_train[\"ABSTRACT\"] = X_train[\"ABSTRACT\"].apply(remove_punc)\nX_test[\"ABSTRACT\"] = X_test[\"ABSTRACT\"].apply(remove_punc)\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:31.871347Z","iopub.execute_input":"2024-03-25T05:45:31.871668Z","iopub.status.idle":"2024-03-25T05:45:31.948782Z","shell.execute_reply.started":"2024-03-25T05:45:31.871638Z","shell.execute_reply":"2024-03-25T05:45:31.947399Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                                ABSTRACT\n10864  recent work has explored a syntactic abilities...\n6518   this research presents an innovative and uniqu...\n11212  recently  a fabrication of cdse nanoplatelets ...\n3589   we present the simple  self consistent model t...\n6927   imposing constraints on a output of the deep n...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABSTRACT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10864</th>\n      <td>recent work has explored a syntactic abilities...</td>\n    </tr>\n    <tr>\n      <th>6518</th>\n      <td>this research presents an innovative and uniqu...</td>\n    </tr>\n    <tr>\n      <th>11212</th>\n      <td>recently  a fabrication of cdse nanoplatelets ...</td>\n    </tr>\n    <tr>\n      <th>3589</th>\n      <td>we present the simple  self consistent model t...</td>\n    </tr>\n    <tr>\n      <th>6927</th>\n      <td>imposing constraints on a output of the deep n...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Removing Stop Words","metadata":{}},{"cell_type":"markdown","source":"- Since, we are using machine learning based algorithms, then sequence of the words doesn't matters.\n- Removing stopwords can significantly enhance the algorithm's focus on meaningful words, thereby improving classification accuracy.","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nstopwords = stopwords.words(\"english\")","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:43.297555Z","iopub.execute_input":"2024-03-25T05:45:43.297884Z","iopub.status.idle":"2024-03-25T05:45:44.057185Z","shell.execute_reply.started":"2024-03-25T05:45:43.297854Z","shell.execute_reply":"2024-03-25T05:45:44.056078Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"def remove_stopwords(text):\n    temp = []\n    for word in text.split():\n        if word not in stopwords:\n            temp.append(word)\n    temp = \" \".join(temp)\n    return temp","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:44.058318Z","iopub.execute_input":"2024-03-25T05:45:44.058573Z","iopub.status.idle":"2024-03-25T05:45:44.063045Z","shell.execute_reply.started":"2024-03-25T05:45:44.058549Z","shell.execute_reply":"2024-03-25T05:45:44.062126Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"X_train[\"ABSTRACT\"] = X_train[\"ABSTRACT\"].apply(remove_stopwords)\nX_test[\"ABSTRACT\"] = X_test[\"ABSTRACT\"].apply(remove_stopwords)\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:44.064230Z","iopub.execute_input":"2024-03-25T05:45:44.064484Z","iopub.status.idle":"2024-03-25T05:45:47.859268Z","shell.execute_reply.started":"2024-03-25T05:45:44.064462Z","shell.execute_reply":"2024-03-25T05:45:47.858382Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                                ABSTRACT\n10864  recent work explored syntactic abilities rnns ...\n6518   research presents innovative unique way solvin...\n11212  recently fabrication cdse nanoplatelets became...\n3589   present simple self consistent model predict m...\n6927   imposing constraints output deep neural net on...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABSTRACT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10864</th>\n      <td>recent work explored syntactic abilities rnns ...</td>\n    </tr>\n    <tr>\n      <th>6518</th>\n      <td>research presents innovative unique way solvin...</td>\n    </tr>\n    <tr>\n      <th>11212</th>\n      <td>recently fabrication cdse nanoplatelets became...</td>\n    </tr>\n    <tr>\n      <th>3589</th>\n      <td>present simple self consistent model predict m...</td>\n    </tr>\n    <tr>\n      <th>6927</th>\n      <td>imposing constraints output deep neural net on...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Stemming","metadata":{}},{"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer\nimport time\n\nps = PorterStemmer()\ndef stemming(word):\n    return \" \".join([ps.stem(word) for word in word.split()])","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:47.860578Z","iopub.execute_input":"2024-03-25T05:45:47.860906Z","iopub.status.idle":"2024-03-25T05:45:47.866284Z","shell.execute_reply.started":"2024-03-25T05:45:47.860875Z","shell.execute_reply":"2024-03-25T05:45:47.865344Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"X_train[\"ABSTRACT\"] = X_train[\"ABSTRACT\"].apply(stemming)\nX_test[\"ABSTRACT\"] = X_test[\"ABSTRACT\"].apply(stemming)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:45:47.867258Z","iopub.execute_input":"2024-03-25T05:45:47.868371Z","iopub.status.idle":"2024-03-25T05:46:23.695292Z","shell.execute_reply.started":"2024-03-25T05:45:47.868317Z","shell.execute_reply":"2024-03-25T05:46:23.694403Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Tokenization\n","metadata":{}},{"cell_type":"code","source":"def tekenize(text):\n    return text.split()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:46:23.696473Z","iopub.execute_input":"2024-03-25T05:46:23.696801Z","iopub.status.idle":"2024-03-25T05:46:23.701544Z","shell.execute_reply.started":"2024-03-25T05:46:23.696771Z","shell.execute_reply":"2024-03-25T05:46:23.700626Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"X_train[\"ABSTRACT\"] = X_train[\"ABSTRACT\"].apply(tekenize)\nX_test[\"ABSTRACT\"] = X_test[\"ABSTRACT\"].apply(tekenize)\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:46:23.702735Z","iopub.execute_input":"2024-03-25T05:46:23.703114Z","iopub.status.idle":"2024-03-25T05:46:23.843591Z","shell.execute_reply.started":"2024-03-25T05:46:23.703086Z","shell.execute_reply":"2024-03-25T05:46:23.842419Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                                ABSTRACT\n10864  [recent, work, explor, syntact, abil, rnn, hel...\n6518   [research, present, innov, uniqu, way, solv, a...\n11212  [recent, fabric, cdse, nanoplatelet, becam, im...\n3589   [present, simpl, self, consist, model, predict...\n6927   [impos, constraint, output, deep, neural, net,...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABSTRACT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10864</th>\n      <td>[recent, work, explor, syntact, abil, rnn, hel...</td>\n    </tr>\n    <tr>\n      <th>6518</th>\n      <td>[research, present, innov, uniqu, way, solv, a...</td>\n    </tr>\n    <tr>\n      <th>11212</th>\n      <td>[recent, fabric, cdse, nanoplatelet, becam, im...</td>\n    </tr>\n    <tr>\n      <th>3589</th>\n      <td>[present, simpl, self, consist, model, predict...</td>\n    </tr>\n    <tr>\n      <th>6927</th>\n      <td>[impos, constraint, output, deep, neural, net,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Vectorize","metadata":{}},{"cell_type":"code","source":"import gensim\n\ncorpus = list(X_train[\"ABSTRACT\"])\nlen(corpus)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:46:33.841319Z","iopub.execute_input":"2024-03-25T05:46:33.841738Z","iopub.status.idle":"2024-03-25T05:46:41.916591Z","shell.execute_reply.started":"2024-03-25T05:46:33.841703Z","shell.execute_reply":"2024-03-25T05:46:41.915213Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"11203"},"metadata":{}}]},{"cell_type":"code","source":"vector_size = 100\nmodel= gensim.models.Word2Vec(corpus,\n    window = 4,\n    min_count= 1,\n    vector_size = vector_size,\n    workers = 4\n    )\nmodel.train(corpus, total_examples = model.corpus_count,epochs=model.epochs)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:46:41.921385Z","iopub.execute_input":"2024-03-25T05:46:41.921913Z","iopub.status.idle":"2024-03-25T05:46:49.890135Z","shell.execute_reply.started":"2024-03-25T05:46:41.921883Z","shell.execute_reply":"2024-03-25T05:46:49.889469Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"(5598936, 6034605)"},"metadata":{}}]},{"cell_type":"code","source":"def vectorize_abstract(tokenized_list):\n    text = [word for word in tokenized_list if word in model.wv.index_to_key]\n    return np.mean(model.wv[text],axis = 0)\n\nX_train_vec = X_train.copy()\nX_test_vec = X_test.copy()\nX_train_vec[\"ABSTRACT\"] = X_train[\"ABSTRACT\"].apply(vectorize_abstract).tolist()\nX_test_vec[\"ABSTRACT\"] = X_test[\"ABSTRACT\"].apply(vectorize_abstract).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:46:49.890844Z","iopub.execute_input":"2024-03-25T05:46:49.891052Z","iopub.status.idle":"2024-03-25T05:47:22.595051Z","shell.execute_reply.started":"2024-03-25T05:46:49.891032Z","shell.execute_reply":"2024-03-25T05:47:22.593925Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"X_train_in = pd.DataFrame(X_train_vec['ABSTRACT'].tolist())\nX_test_in = pd.DataFrame(X_test_vec['ABSTRACT'].tolist())\nX_train_in","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:47:22.596399Z","iopub.execute_input":"2024-03-25T05:47:22.596775Z","iopub.status.idle":"2024-03-25T05:47:22.946446Z","shell.execute_reply.started":"2024-03-25T05:47:22.596740Z","shell.execute_reply":"2024-03-25T05:47:22.945534Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"             0         1         2         3         4         5         6   \\\n0      0.434169  0.497067 -0.137996  0.392593  0.312611 -0.447021 -0.561747   \n1     -0.160964  0.139512  0.257017  0.463671  0.298604 -0.496796 -0.603057   \n2     -0.171138 -0.068740  0.409032  0.522558  0.343593 -0.438994 -0.086851   \n3     -0.022124  0.510649  0.468935  0.007119  0.411399 -0.757856  0.052787   \n4     -0.172022  0.440761  0.153715  0.407142  0.535757 -0.203469 -0.454783   \n...         ...       ...       ...       ...       ...       ...       ...   \n11198  0.008307  0.161205  0.191842 -0.032319  0.407150 -0.289143 -0.473460   \n11199 -0.171733  0.343394  0.284930 -0.295850  0.581179 -0.096978 -0.418676   \n11200  0.084813  0.568134  0.007406 -0.235805  0.351063  0.035523 -0.446390   \n11201 -0.177524  0.175197 -0.006524  0.147917  0.473700 -0.232786 -0.118700   \n11202 -0.037488  0.323165  0.285534  0.456509  0.412651 -0.401165 -0.709307   \n\n             7         8         9   ...        90        91        92  \\\n0      0.431754 -0.067340 -0.066511  ...  0.550199 -0.319110 -0.202827   \n1      0.138651 -0.251160 -0.129881  ...  0.339514  0.055877 -0.075594   \n2      0.389179 -0.380887 -0.080176  ... -0.049513  0.194185 -0.127655   \n3      0.376282 -0.389018  0.376670  ... -0.104888 -0.372516 -0.272091   \n4      0.477946 -0.049865 -0.028681  ...  0.340345 -0.160666  0.030015   \n...         ...       ...       ...  ...       ...       ...       ...   \n11198  0.455931 -0.238869  0.030997  ...  0.337980  0.325986 -0.051514   \n11199  0.502478 -0.148693 -0.356061  ... -0.028691  0.403866 -0.146093   \n11200  0.316369 -0.388147 -0.002179  ...  0.008354 -0.013045 -0.310144   \n11201  0.315585 -0.148813  0.097392  ...  0.317880  0.130595 -0.059054   \n11202  0.185858  0.045594 -0.251824  ...  0.298371  0.206419 -0.405503   \n\n             93        94        95        96        97        98        99  \n0     -0.440934  0.331354 -0.154107  0.023623 -0.264015  0.334725 -0.090740  \n1     -0.252529  0.716801 -0.008356 -0.055552 -0.750366 -0.016194 -0.192978  \n2     -0.017834  0.720038 -0.127321  0.198543 -0.333079 -0.211227  0.208561  \n3     -0.169860  0.590384  0.018837  0.090778 -0.292178  0.041225  0.842303  \n4     -0.167863  0.305392 -0.336355 -0.035989 -0.747500 -0.088499  0.247618  \n...         ...       ...       ...       ...       ...       ...       ...  \n11198  0.057061  0.418096 -0.002156  0.041988 -0.531555  0.122515  0.022464  \n11199 -0.310352  0.679379 -0.105074  0.318533 -0.688415 -0.007885  0.066226  \n11200 -0.485191  1.002162 -0.269859  0.265832 -0.544944 -0.106754 -0.052202  \n11201 -0.164593  0.710671 -0.140382  0.194303 -0.703287  0.235591 -0.017372  \n11202 -0.565220  0.504244 -0.418440  0.164584 -0.909170 -0.210544 -0.317734  \n\n[11203 rows x 100 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.434169</td>\n      <td>0.497067</td>\n      <td>-0.137996</td>\n      <td>0.392593</td>\n      <td>0.312611</td>\n      <td>-0.447021</td>\n      <td>-0.561747</td>\n      <td>0.431754</td>\n      <td>-0.067340</td>\n      <td>-0.066511</td>\n      <td>...</td>\n      <td>0.550199</td>\n      <td>-0.319110</td>\n      <td>-0.202827</td>\n      <td>-0.440934</td>\n      <td>0.331354</td>\n      <td>-0.154107</td>\n      <td>0.023623</td>\n      <td>-0.264015</td>\n      <td>0.334725</td>\n      <td>-0.090740</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.160964</td>\n      <td>0.139512</td>\n      <td>0.257017</td>\n      <td>0.463671</td>\n      <td>0.298604</td>\n      <td>-0.496796</td>\n      <td>-0.603057</td>\n      <td>0.138651</td>\n      <td>-0.251160</td>\n      <td>-0.129881</td>\n      <td>...</td>\n      <td>0.339514</td>\n      <td>0.055877</td>\n      <td>-0.075594</td>\n      <td>-0.252529</td>\n      <td>0.716801</td>\n      <td>-0.008356</td>\n      <td>-0.055552</td>\n      <td>-0.750366</td>\n      <td>-0.016194</td>\n      <td>-0.192978</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.171138</td>\n      <td>-0.068740</td>\n      <td>0.409032</td>\n      <td>0.522558</td>\n      <td>0.343593</td>\n      <td>-0.438994</td>\n      <td>-0.086851</td>\n      <td>0.389179</td>\n      <td>-0.380887</td>\n      <td>-0.080176</td>\n      <td>...</td>\n      <td>-0.049513</td>\n      <td>0.194185</td>\n      <td>-0.127655</td>\n      <td>-0.017834</td>\n      <td>0.720038</td>\n      <td>-0.127321</td>\n      <td>0.198543</td>\n      <td>-0.333079</td>\n      <td>-0.211227</td>\n      <td>0.208561</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.022124</td>\n      <td>0.510649</td>\n      <td>0.468935</td>\n      <td>0.007119</td>\n      <td>0.411399</td>\n      <td>-0.757856</td>\n      <td>0.052787</td>\n      <td>0.376282</td>\n      <td>-0.389018</td>\n      <td>0.376670</td>\n      <td>...</td>\n      <td>-0.104888</td>\n      <td>-0.372516</td>\n      <td>-0.272091</td>\n      <td>-0.169860</td>\n      <td>0.590384</td>\n      <td>0.018837</td>\n      <td>0.090778</td>\n      <td>-0.292178</td>\n      <td>0.041225</td>\n      <td>0.842303</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.172022</td>\n      <td>0.440761</td>\n      <td>0.153715</td>\n      <td>0.407142</td>\n      <td>0.535757</td>\n      <td>-0.203469</td>\n      <td>-0.454783</td>\n      <td>0.477946</td>\n      <td>-0.049865</td>\n      <td>-0.028681</td>\n      <td>...</td>\n      <td>0.340345</td>\n      <td>-0.160666</td>\n      <td>0.030015</td>\n      <td>-0.167863</td>\n      <td>0.305392</td>\n      <td>-0.336355</td>\n      <td>-0.035989</td>\n      <td>-0.747500</td>\n      <td>-0.088499</td>\n      <td>0.247618</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11198</th>\n      <td>0.008307</td>\n      <td>0.161205</td>\n      <td>0.191842</td>\n      <td>-0.032319</td>\n      <td>0.407150</td>\n      <td>-0.289143</td>\n      <td>-0.473460</td>\n      <td>0.455931</td>\n      <td>-0.238869</td>\n      <td>0.030997</td>\n      <td>...</td>\n      <td>0.337980</td>\n      <td>0.325986</td>\n      <td>-0.051514</td>\n      <td>0.057061</td>\n      <td>0.418096</td>\n      <td>-0.002156</td>\n      <td>0.041988</td>\n      <td>-0.531555</td>\n      <td>0.122515</td>\n      <td>0.022464</td>\n    </tr>\n    <tr>\n      <th>11199</th>\n      <td>-0.171733</td>\n      <td>0.343394</td>\n      <td>0.284930</td>\n      <td>-0.295850</td>\n      <td>0.581179</td>\n      <td>-0.096978</td>\n      <td>-0.418676</td>\n      <td>0.502478</td>\n      <td>-0.148693</td>\n      <td>-0.356061</td>\n      <td>...</td>\n      <td>-0.028691</td>\n      <td>0.403866</td>\n      <td>-0.146093</td>\n      <td>-0.310352</td>\n      <td>0.679379</td>\n      <td>-0.105074</td>\n      <td>0.318533</td>\n      <td>-0.688415</td>\n      <td>-0.007885</td>\n      <td>0.066226</td>\n    </tr>\n    <tr>\n      <th>11200</th>\n      <td>0.084813</td>\n      <td>0.568134</td>\n      <td>0.007406</td>\n      <td>-0.235805</td>\n      <td>0.351063</td>\n      <td>0.035523</td>\n      <td>-0.446390</td>\n      <td>0.316369</td>\n      <td>-0.388147</td>\n      <td>-0.002179</td>\n      <td>...</td>\n      <td>0.008354</td>\n      <td>-0.013045</td>\n      <td>-0.310144</td>\n      <td>-0.485191</td>\n      <td>1.002162</td>\n      <td>-0.269859</td>\n      <td>0.265832</td>\n      <td>-0.544944</td>\n      <td>-0.106754</td>\n      <td>-0.052202</td>\n    </tr>\n    <tr>\n      <th>11201</th>\n      <td>-0.177524</td>\n      <td>0.175197</td>\n      <td>-0.006524</td>\n      <td>0.147917</td>\n      <td>0.473700</td>\n      <td>-0.232786</td>\n      <td>-0.118700</td>\n      <td>0.315585</td>\n      <td>-0.148813</td>\n      <td>0.097392</td>\n      <td>...</td>\n      <td>0.317880</td>\n      <td>0.130595</td>\n      <td>-0.059054</td>\n      <td>-0.164593</td>\n      <td>0.710671</td>\n      <td>-0.140382</td>\n      <td>0.194303</td>\n      <td>-0.703287</td>\n      <td>0.235591</td>\n      <td>-0.017372</td>\n    </tr>\n    <tr>\n      <th>11202</th>\n      <td>-0.037488</td>\n      <td>0.323165</td>\n      <td>0.285534</td>\n      <td>0.456509</td>\n      <td>0.412651</td>\n      <td>-0.401165</td>\n      <td>-0.709307</td>\n      <td>0.185858</td>\n      <td>0.045594</td>\n      <td>-0.251824</td>\n      <td>...</td>\n      <td>0.298371</td>\n      <td>0.206419</td>\n      <td>-0.405503</td>\n      <td>-0.565220</td>\n      <td>0.504244</td>\n      <td>-0.418440</td>\n      <td>0.164584</td>\n      <td>-0.909170</td>\n      <td>-0.210544</td>\n      <td>-0.317734</td>\n    </tr>\n  </tbody>\n</table>\n<p>11203 rows × 100 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Modele selection and Evaluation","metadata":{}},{"cell_type":"markdown","source":"## 1.Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, make_scorer\nfrom sklearn.model_selection import GridSearchCV\n\nrfc = RandomForestClassifier(max_depth = 5,n_jobs = -1)\nrfc.fit(X_train_in,y_train)\ny_pred_train = rfc.predict(X_train_in)\ny_pred = rfc.predict(X_test_in)\n\nf1_score(y_train,y_pred_train,average = \"macro\"),f1_score(y_test,y_pred,average = \"macro\")","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:47:24.349057Z","iopub.execute_input":"2024-03-25T05:47:24.349855Z","iopub.status.idle":"2024-03-25T05:47:27.055166Z","shell.execute_reply.started":"2024-03-25T05:47:24.349782Z","shell.execute_reply":"2024-03-25T05:47:27.053811Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(0.7738344286296932, 0.7598236158427114)"},"metadata":{}}]},{"cell_type":"markdown","source":"window 1 , 300 (0.7688740952166848, 0.7556735556754897)\n\nwindow 3 , 300(0.7754760431286739, 0.7696386951182455)\n.7686592700639805, 0.7532132585105826)\n\nwindow 7 , 300(0.7751692803647058, 0.7589523639952945)\n\nw = 10 , 100 (0.7641491463691902, 0.7505651480280441)","metadata":{}},{"cell_type":"markdown","source":"## 2.Adaboost","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import f1_score, make_scorer\nfrom sklearn.multioutput import MultiOutputClassifier\n\nabc = MultiOutputClassifier(AdaBoostClassifier(n_estimators = 100, learning_rate = 0.5), n_jobs=-1)\n\nabc.fit(X_train_in,y_train)\ny_pred_train = abc.predict(X_train_in)\ny_pred = abc.predict(X_test_in)\nf1_score(y_train,y_pred_train,average = \"macro\"),f1_score(y_test,y_pred,average = \"macro\")","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:47:27.057756Z","iopub.execute_input":"2024-03-25T05:47:27.058173Z","iopub.status.idle":"2024-03-25T05:47:48.399253Z","shell.execute_reply.started":"2024-03-25T05:47:27.058144Z","shell.execute_reply":"2024-03-25T05:47:48.398454Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(0.8295371152981884, 0.8096038498691326)"},"metadata":{}}]},{"cell_type":"markdown","source":"## 3.Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:47:48.400305Z","iopub.execute_input":"2024-03-25T05:47:48.400984Z","iopub.status.idle":"2024-03-25T05:47:48.407755Z","shell.execute_reply.started":"2024-03-25T05:47:48.400956Z","shell.execute_reply":"2024-03-25T05:47:48.406606Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Since GaussianNB can only handle 1d-array as y-dataset. So, fitting 4 different models in loop.","metadata":{}},{"cell_type":"code","source":"test_scores = []\nfor i in range(1,5):\n    nbc= GaussianNB()\n    nbc.fit(X_train_in,globals()[f\"y{i}_train\"])\n    y_pred_train = nbc.predict(X_train_in)\n    y_pred = nbc.predict(X_test_in)\n    print(\"train: \",f1_score(y_pred_train, globals()[f\"y{i}_train\"]))\n    print(\"test: \",f1_score(y_pred, globals()[f\"y{i}_test\"]))\n    test_scores.append(f1_score(y_pred, globals()[f\"y{i}_test\"]))\nprint(\"Average F1 score in test data:\",np.mean(test_scores))","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:47:48.409339Z","iopub.execute_input":"2024-03-25T05:47:48.409786Z","iopub.status.idle":"2024-03-25T05:47:48.602424Z","shell.execute_reply.started":"2024-03-25T05:47:48.409750Z","shell.execute_reply":"2024-03-25T05:47:48.601175Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"train:  0.7910994272838231\ntest:  0.7838338895068595\ntrain:  0.7481722177091795\ntest:  0.7455919395465995\ntrain:  0.9313531353135314\ntest:  0.9312169312169313\ntrain:  0.6306660499537464\ntest:  0.6561938958707361\nAverage F1 score in test data: 0.7792091640352816\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 4.XGBoost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb = RandomForestClassifier(max_depth = 5,n_jobs = -1)\n\nxgb.fit(X_train_in,y_train)\ny_pred_train = xgb.predict(X_train_in)\ny_pred = xgb.predict(X_test_in)\nf1_score(y_train,y_pred_train,average = \"macro\"),f1_score(y_test,y_pred,average = \"macro\")","metadata":{"execution":{"iopub.status.busy":"2024-03-25T05:47:58.587923Z","iopub.execute_input":"2024-03-25T05:47:58.588181Z","iopub.status.idle":"2024-03-25T05:48:01.356111Z","shell.execute_reply.started":"2024-03-25T05:47:58.588157Z","shell.execute_reply":"2024-03-25T05:48:01.354994Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"(0.7691605559879291, 0.7583907431783062)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Optimizing Hyperparameters for Adaboost with Word2Vec","metadata":{}},{"cell_type":"code","source":"for vector_size in [100,200,300]:\n    for window in [4,7,10]:\n        for n_estimators in [50,100]:\n            for learning_rate in [0.1,0.5,1]:\n                t = time.time()\n                model= gensim.models.Word2Vec(corpus,window = window,\n                       min_count= 1,\n                       vector_size = vector_size,\n                       workers = 4)\n                model.train(corpus, total_examples = model.corpus_count,epochs=model.epochs)\n\n                def vectorize_abstract(tokenized_list):\n                    text = [word for word in tokenized_list if word in model.wv.index_to_key]\n                    return np.mean(model.wv[text],axis = 0)\n                \n                X_train_vec = X_train.copy()\n                X_test_vec = X_test.copy()\n                X_train_vec[\"ABSTRACT\"] = X_train[\"ABSTRACT\"].apply(vectorize_abstract)\n                X_test_vec[\"ABSTRACT\"] = X_test[\"ABSTRACT\"].apply(vectorize_abstract)\n                X_train_in = pd.DataFrame(X_train_vec['ABSTRACT'].tolist())\n                X_test_in = pd.DataFrame(X_test_vec['ABSTRACT'].tolist())\n\n                classifier = MultiOutputClassifier(AdaBoostClassifier(n_estimators = n_estimators, learning_rate = learning_rate), n_jobs=-1)\n                classifier.fit(X_train_in,y_train)\n                y_pred_train = classifier.predict(X_train_in)\n                y_pred = classifier.predict(X_test_in)\n                print(time.time()-t)\n                print(\"Hyperparameters: \",\"vector_size = \",vector_size,\"window = \",window,\"n_estimator = \",n_estimators,\"learning_rate = \",learning_rate)\n                print(\"Train score: \",f1_score(y_train,y_pred_train,average = \"macro\"),\"Test score: \", f1_score(y_test,y_pred,average = \"macro\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hyperparameters:  vector_size =  100 window =  4 n_estimator =  50 learning_rate =  0.1\nTrain score:  0.7888647954089151 Test score:  0.7833197806603203\n\nHyperparameters:  vector_size =  100 window =  4 n_estimator =  50 learning_rate =  0.5\nTrain score:  0.8183276736697701 Test score:  0.8075680903034081\n\nHyperparameters:  vector_size =  100 window =  4 n_estimator =  50 learning_rate =  1\nTrain score:  0.8190600566205557 Test score:  0.8008788838377146\n\nHyperparameters:  vector_size =  100 window =  4 n_estimator =  100 learning_rate =  0.1\nTrain score:  0.8044657044523095 Test score:  0.7985527473334413\n\nHyperparameters:  vector_size =  100 window =  4 n_estimator =  100 learning_rate =  0.5\nTrain score:  0.8287248232427425 Test score:  0.8141099215691027\n\nHyperparameters:  vector_size =  100 window =  4 n_estimator =  100 learning_rate =  1\nTrain score:  0.8371698315512807 Test score:  0.8041273834602976\n\nHyperparameters:  vector_size =  100 window =  7 n_estimator =  50 learning_rate =  0.1\nTrain score:  0.7908713844636447 Test score:  0.7866689781249941\n\nHyperparameters:  vector_size =  100 window =  7 n_estimator =  50 learning_rate =  0.5\nTrain score:  0.8214136108305716 Test score:  0.81392822408212\n\nHyperparameters:  vector_size =  100 window =  7 n_estimator =  50 learning_rate =  1\nTrain score:  0.8247351564218608 Test score:  0.8074778006134192\n\nHyperparameters:  vector_size =  100 window =  7 n_estimator =  100 learning_rate =  0.1\nTrain score:  0.8115296270075976 Test score:  0.8074653844202999\n\nHyperparameters:  vector_size =  100 window =  7 n_estimator =  100 learning_rate =  0.5\nTrain score:  0.8329382795515746 Test score:  0.8212894855427767\n\nHyperparameters:  vector_size =  100 window =  7 n_estimator =  100 learning_rate =  1\nTrain score:  0.8389373842595793 Test score:  0.8190983095827689\n\nHyperparameters:  vector_size =  100 window =  10 n_estimator =  50 learning_rate =  0.1\nTrain score:  0.7937267167437966 Test score:  0.7951062282192839\n\nHyperparameters:  vector_size =  100 window =  10 n_estimator =  50 learning_rate =  0.5\nTrain score:  0.8227459107308934 Test score:  0.8097438321472485\n\nHyperparameters:  vector_size =  100 window =  10 n_estimator =  50 learning_rate =  1\nTrain score:  0.8236634941993541 Test score:  0.8068745777322421\n\nHyperparameters:  vector_size =  100 window =  10 n_estimator =  100 learning_rate =  0.1\nTrain score:  0.8089049437543426 Test score:  0.8030716244434193\n\nHyperparameters:  vector_size =  100 window =  10 n_estimator =  100 learning_rate =  0.5\nTrain score:  0.8333416334890049 Test score:  0.8171821653512464\n\nHyperparameters:  vector_size =  100 window =  10 n_estimator =  100 learning_rate =  1\nTrain score:  0.8409969240931676 Test score:  0.8115190857833857\n\nHyperparameters:  vector_size =  200 window =  4 n_estimator =  50 learning_rate =  0.1\nTrain score:  0.7946991085349088 Test score:  0.7865253527033136\n\nHyperparameters:  vector_size =  200 window =  4 n_estimator =  50 learning_rate =  0.5\nTrain score:  0.8212818989011118 Test score:  0.8129098047356516\n\nHyperparameters:  vector_size =  200 window =  4 n_estimator =  50 learning_rate =  1\nTrain score:  0.8232561792761892 Test score:  0.8012920589635786\n\nHyperparameters:  vector_size =  200 window =  4 n_estimator =  100 learning_rate =  0.1\nTrain score:  0.8105600435838346 Test score:  0.8046765400054733\n\nHyperparameters:  vector_size =  200 window =  4 n_estimator =  100 learning_rate =  0.5\nTrain score:  0.834447949666691 Test score:  0.8168334589395274\n\nHyperparameters:  vector_size =  200 window =  4 n_estimator =  100 learning_rate =  1\nTrain score:  0.8401692843178505 Test score:  0.8097146468257053\n\nHyperparameters:  vector_size =  200 window =  7 n_estimator =  50 learning_rate =  0.1\nTrain score:  0.7997661735177206 Test score:  0.7967999887453208\n\nHyperparameters:  vector_size =  200 window =  7 n_estimator =  50 learning_rate =  0.5\nTrain score:  0.8215898166690483 Test score:  0.8080544260315742\n\nHyperparameters:  vector_size =  200 window =  7 n_estimator =  50 learning_rate =  1\nTrain score:  0.8242195330765387 Test score:  0.8106114167362274\n\nHyperparameters:  vector_size =  200 window =  7 n_estimator =  100 learning_rate =  0.1\nTrain score:  0.8143031033640369 Test score:  0.8107102794654606\n\nHyperparameters:  vector_size =  200 window =  7 n_estimator =  100 learning_rate =  0.5\nTrain score:  0.8360911601142774 Test score:  0.8197034867549734\n\nHyperparameters:  vector_size =  200 window =  7 n_estimator =  100 learning_rate =  1\nTrain score:  0.8439004036437036 Test score:  0.8111898505116573\n\nHyperparameters:  vector_size =  200 window =  10 n_estimator =  50 learning_rate =  0.1\nTrain score:  0.7991874187180988 Test score:  0.7985241632521124\n\nHyperparameters:  vector_size =  200 window =  10 n_estimator =  50 learning_rate =  0.5\nTrain score:  0.8230168123537445 Test score:  0.8163129392463889\n\nHyperparameters:  vector_size =  200 window =  10 n_estimator =  50 learning_rate =  1\nTrain score:  0.8277082146356952 Test score:  0.8107588446912674\n\nHyperparameters:  vector_size =  200 window =  10 n_estimator =  100 learning_rate =  0.1\nTrain score:  0.8143375249695566 Test score:  0.8107023516452269\n\nHyperparameters:  vector_size =  200 window =  10 n_estimator =  100 learning_rate =  0.5\nTrain score:  0.8361847158508455 Test score:  0.8213002351138347\n\nHyperparameters:  vector_size =  200 window =  10 n_estimator =  100 learning_rate =  1\nTrain score:  0.8453509501612227 Test score:  0.8129616926711318\n\nHyperparameters:  vector_size =  300 window =  4 n_estimator =  50 learning_rate =  0.1\nTrain score:  0.7928245533573252 Test score:  0.7902557094153544\n\nHyperparameters:  vector_size =  300 window =  4 n_estimator =  50 learning_rate =  0.5\nTrain score:  0.8223704691421638 Test score:  0.8098302391690684\n\nHyperparameters:  vector_size =  300 window =  4 n_estimator =  50 learning_rate =  1\nTrain score:  0.822442867600612 Test score:  0.8058847028746517\n\nHyperparameters:  vector_size =  300 window =  4 n_estimator =  100 learning_rate =  0.1\nTrain score:  0.8160158412321356 Test score:  0.8128208075327648\n\nHyperparameters:  vector_size =  300 window =  4 n_estimator =  100 learning_rate =  0.5\nTrain score:  0.8385322682633494 Test score:  0.8144937793525562\n\nHyperparameters:  vector_size =  300 window =  4 n_estimator =  100 learning_rate =  1\nTrain score:  0.8429703320983177 Test score:  0.8090254169993912\n\nHyperparameters:  vector_size =  300 window =  7 n_estimator =  50 learning_rate =  0.1\nTrain score:  0.7984635148913778 Test score:  0.7903276535154157\n\nHyperparameters:  vector_size =  300 window =  7 n_estimator =  50 learning_rate =  0.5\nTrain score:  0.8241265702476338 Test score:  0.8153644621972239\n\nHyperparameters:  vector_size =  300 window =  7 n_estimator =  50 learning_rate =  1\nTrain score:  0.8271812637847401 Test score:  0.8085161112950283\n\nHyperparameters:  vector_size =  300 window =  7 n_estimator =  100 learning_rate =  0.1\nTrain score:  0.812241735355691 Test score:  0.8096401217861039\n\nHyperparameters:  vector_size =  300 window =  7 n_estimator =  100 learning_rate =  0.5\nTrain score:  0.8406403759143766 Test score:  0.8139381447616445\n\nHyperparameters:  vector_size =  300 window =  7 n_estimator =  100 learning_rate =  1\nTrain score:  0.8449886939572137 Test score:  0.8079062394377027\n\nHyperparameters:  vector_size =  300 window =  10 n_estimator =  50 learning_rate =  0.1\nTrain score:  0.8011211885503766 Test score:  0.7992571041545528\n\nHyperparameters:  vector_size =  300 window =  10 n_estimator =  50 learning_rate =  0.5\nTrain score:  0.8228099522411267 Test score:  0.8114610537975122\n\nHyperparameters:  vector_size =  300 window =  10 n_estimator =  50 learning_rate =  1\nTrain score:  0.8281410959698303 Test score:  0.8089894901988152\n\nHyperparameters:  vector_size =  300 window =  10 n_estimator =  100 learning_rate =  0.1\nTrain score:  0.8184711618611453 Test score:  0.8151350929504934\n\nHyperparameters:  vector_size =  300 window =  10 n_estimator =  100 learning_rate =  0.5\nTrain score:  0.8396558446887468 Test score:  0.8238581528730363\n\nHyperparameters:  vector_size =  300 window =  10 n_estimator =  100 learning_rate =  1\nTrain score:  0.8486119727912368 Test score:  0.8156460238975898","metadata":{}},{"cell_type":"markdown","source":"### Best Score \n\n- Test score:  0.8238581528730363 with Train score:  0.8396558446887468\n\n- Adaboost with Hyperparameters: n_estimator = 100,learning_rate =  0.5\n- Word2Vec Hyperparameters: vector_size = 300, window =  10\n\nThis is best score as it is not overfitted and have highest test accuracy. \n ","metadata":{}}]}